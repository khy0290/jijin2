import streamlit as st
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score
import numpy as np

# --- 1. Random Forest ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜ ---
@st.cache_resource # ëª¨ë¸ì„ ìºì‹±í•˜ì—¬ íŒŒì¼ ì—…ë¡œë“œë§ˆë‹¤ ì¬í•™ìŠµí•˜ëŠ” ê²ƒì„ ë°©ì§€
def train_random_forest_model(df):
    """
    ì—…ë¡œë“œëœ ë°ì´í„°ë¡œ Random Forest ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    # 1. íŠ¹ì§•(Features) ë° ë ˆì´ë¸”(Label) ì •ì˜
    # ì“°ë‚˜ë¯¸ ì˜ˆì¸¡ì— ì‚¬ìš©ë  ì…ë ¥ ë³€ìˆ˜: distance_to_coast ì œì™¸
    FEATURES = ['magnitude', 'depth', 'latitude', 'longitude']
    # ì˜ˆì¸¡í•  ì¶œë ¥ ë³€ìˆ˜ (0: ë¯¸ë°œìƒ, 1: ë°œìƒ)
    LABEL = 'tsunami'
    
    # í•„ìˆ˜ ì—´ì´ ë°ì´í„°ì— í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
    missing_cols = [col for col in FEATURES + [LABEL] if col not in df.columns]
    if missing_cols:
        st.error(f"í•„ìˆ˜ ì—´ì´ ë°ì´í„°ì— ì—†ìŠµë‹ˆë‹¤: {', '.join(missing_cols)}")
        return None, None, None, None, None

    # ë°ì´í„° ë¶„ë¦¬
    X = df[FEATURES]
    y = df[LABEL]

    # í•™ìŠµ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ë¦¬ (ì˜ˆì‹œ: 80% í•™ìŠµ, 20% í…ŒìŠ¤íŠ¸)
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

    # 2. Random Forest ëª¨ë¸ ì´ˆê¸°í™” ë° í•™ìŠµ
    model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')
    model.fit(X_train, y_train)

    # 3. ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ (í…ŒìŠ¤íŠ¸ ë°ì´í„° ì‚¬ìš©)
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    report = classification_report(y_test, y_pred, output_dict=True)

    return model, accuracy, report, FEATURES, X

# --- 2. ì“°ë‚˜ë¯¸ ê²½ë³´ ë° ëŒ€í”¼ ìš”ë ¹ ---

def display_tsunami_warning(df_results):
    """
    ì˜ˆì¸¡ëœ ì“°ë‚˜ë¯¸ ë°œìƒ í™•ë¥ ì— ë”°ë¼ ê²½ê³  ë° ëŒ€í”¼ ìš”ë ¹ì„ í‘œì‹œí•©ë‹ˆë‹¤.
    """
    st.subheader("ğŸš¨ ì˜ˆì¸¡ëœ ì“°ë‚˜ë¯¸ ìœ„í—˜ ì§€ìˆ˜ ë° ê²½ë³´")
    
    # 1. í‰ê·  ìœ„í—˜ ì§€ìˆ˜ ê³„ì‚°
    avg_probability = df_results['Tsunami Probability (%)'].mean()
    
    st.metric(label="ì „ì²´ ë°ì´í„°ì…‹ í‰ê·  ì“°ë‚˜ë¯¸ ìœ„í—˜ ì§€ìˆ˜", value=f"{avg_probability:.2f}%", delta_color="off")
    
    # 2. ìœ„í—˜ ë ˆë²¨ì— ë”°ë¥¸ ê²½ê³ 
    
    if avg_probability >= 50:
        st.error("### ğŸ”´ **ë†’ì€ ìœ„í—˜ ê°ì§€!**")
        st.warning("**ì¦‰ì‹œ ê²½ê³„ íƒœì„¸**ë¥¼ ê°–ì¶”ê³ , í•´ë‹¹ ì§€ì—­ì˜ **ê°€ì¥ ë†’ì€ ê³³**ìœ¼ë¡œ ì´ë™í•  ì¤€ë¹„ë¥¼ í•˜ì‹­ì‹œì˜¤. ê³µì‹ ê²½ë³´ë¥¼ ì£¼ì‹œí•˜ì„¸ìš”.")
    elif avg_probability >= 25:
        st.warning("### ğŸŸ  **ì¤‘ê°„ ìœ„í—˜ ê°ì§€!**")
        st.info("ì“°ë‚˜ë¯¸ ë°œìƒ ê°€ëŠ¥ì„±ì´ ìˆìœ¼ë‹ˆ, í•´ì•ˆê°€ ê·¼ì²˜ì—ì„œëŠ” **ê²½ê³„**í•˜ê³  ëŒ€í”¼ ê³„íšì„ í™•ì¸í•˜ì‹­ì‹œì˜¤.")
    else:
        st.success("### ğŸŸ¢ **ë‚®ì€ ìœ„í—˜ ê°ì§€!**")
        st.caption("í˜„ì¬ ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œëŠ” ìœ„í—˜ì´ ë‚®ê²Œ ì˜ˆì¸¡ë©ë‹ˆë‹¤. í•˜ì§€ë§Œ ê°•í•œ ì§€ì§„ ë°œìƒ ì‹œ í•­ìƒ ì£¼ì˜í•˜ì‹­ì‹œì˜¤.")

    st.markdown("---")
    
    # 3. ê³µí†µ ëŒ€í”¼ ìš”ë ¹
    st.subheader("ğŸ“¢ **ì“°ë‚˜ë¯¸ ëŒ€í”¼ ì¼ë°˜ ìš”ë ¹**")
    st.markdown("""
    * **ì¦‰ì‹œ ëŒ€í”¼:** ì§€ì§„ìœ¼ë¡œ ì¸í•´ ë•…ì´ ì‹¬í•˜ê²Œ í”ë“¤ë¦¬ë©´ ì“°ë‚˜ë¯¸ ê²½ë³´ ì—†ì´ë„ ì¦‰ì‹œ ê³ ì§€ëŒ€ë¡œ ëŒ€í”¼í•˜ì‹­ì‹œì˜¤.
    * **ê³ ì§€ëŒ€ ì´ë™:** í•´ì•ˆì—ì„œ ë©€ë¦¬ ë–¨ì–´ì§„ **ê°€ì¥ ë†’ì€ ì§€ì **ìœ¼ë¡œ ì‹ ì†í•˜ê²Œ ì´ë™í•´ì•¼ í•©ë‹ˆë‹¤.
    * **ìš´ì „ ê¸ˆì§€:** ì°¨ëŸ‰ ëŒ€ì‹  **ê±¸ì–´ì„œ** ëŒ€í”¼í•˜ëŠ” ê²ƒì´ ë” ë¹ ë¥´ê³  ì•ˆì „í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    * **ê²½ë³´ í•´ì œ í™•ì¸:** ê³µì‹ì ì¸ **ì“°ë‚˜ë¯¸ ê²½ë³´ í•´ì œ ë°œí‘œ**ê°€ ìˆê¸° ì „ê¹Œì§€ëŠ” ì ˆëŒ€ í•´ì•ˆê°€ë¡œ ëŒì•„ì˜¤ì§€ ë§ˆì„¸ìš”.
    """)
    
    
# --- 3. Streamlit ì•± ë ˆì´ì•„ì›ƒ ì„¤ì • ---

st.set_page_config(page_title="Random Forest ì“°ë‚˜ë¯¸ ì˜ˆì¸¡ ì‹œìŠ¤í…œ", layout="wide")

st.title("ğŸŒ² Random Forest ê¸°ë°˜ ì“°ë‚˜ë¯¸ ìœ„í—˜ ì˜ˆì¸¡ ì‹œë®¬ë ˆì´í„°")
st.markdown("---")

st.header("1. ì§€ì§„ ë°ì´í„° CSV íŒŒì¼ ì—…ë¡œë“œ")
uploaded_file = st.file_uploader(
    "ë‹¤ìŒ ì—´ì„ í¬í•¨í•˜ëŠ” CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”: magnitude, depth, latitude, longitude, **tsunami (0 ë˜ëŠ” 1)**", 
    type="csv"
)

if uploaded_file is not None:
    try:
        # íŒŒì¼ ì½ê¸°
        df = pd.read_csv(uploaded_file)
        st.subheader("ì—…ë¡œë“œëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°")
        st.dataframe(df.head())
        
        if st.button("ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡ ì‹¤í–‰", type="primary"):
            
            # --- ëª¨ë¸ í•™ìŠµ ---
            with st.spinner('ëª¨ë¸ í•™ìŠµ ì¤‘...'):
                model, accuracy, report, FEATURES, X = train_random_forest_model(df)
            
            if model is not None: 
                st.success(f"ëª¨ë¸ í•™ìŠµ ì™„ë£Œ! í…ŒìŠ¤íŠ¸ ì •í™•ë„: **{accuracy:.2f}**")
                
                # --- ì˜ˆì¸¡ ìˆ˜í–‰ ---
                # í´ë˜ìŠ¤ 1 (ì“°ë‚˜ë¯¸ ë°œìƒ)ì˜ í™•ë¥ ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
                probabilities = model.predict_proba(X)[:, 1] 
                
                # ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ì— ì¶”ê°€
                df_results = df.copy()
                df_results['Tsunami Probability (%)'] = probabilities * 100
                
                st.markdown("---")
                st.header("2. ì˜ˆì¸¡ ê²°ê³¼ ë¶„ì„")
                
                # ì˜ˆì¸¡ëœ ìƒìœ„ 10ê°œ ìœ„í—˜ ì´ë²¤íŠ¸ í‘œì‹œ
                st.subheader("ê°€ì¥ ìœ„í—˜ë„ê°€ ë†’ì€ ìƒìœ„ 10ê°œ ì§€ì§„ ì´ë²¤íŠ¸")
                df_results_sorted = df_results.sort_values(by='Tsunami Probability (%)', ascending=False).head(10)
                st.dataframe(df_results_sorted.style.background_gradient(cmap='Reds', subset=['Tsunami Probability (%)']))

                st.markdown("---")
                
                # --- ê²½ë³´ ë° ìš”ë ¹ í‘œì‹œ ---
                display_tsunami_warning(df_results)
                
                st.markdown("---")
                
                # --- ëª¨ë¸ ìƒì„¸ ì •ë³´ (íŠ¹ì§• ì¤‘ìš”ë„) ---
                st.subheader("ëª¨ë¸ í•™ìŠµ ìƒì„¸ ì •ë³´")
                st.caption("Random Forest ëª¨ë¸ì´ ì˜ˆì¸¡ì— ì‚¬ìš©í•œ ê° ë³€ìˆ˜ì˜ ìƒëŒ€ì  ì¤‘ìš”ë„ì…ë‹ˆë‹¤.")
                feature_importances = pd.Series(model.feature_importances_, index=FEATURES).sort_values(ascending=False)
                st.bar_chart(feature_importances)


    except Exception as e:
        st.error(f"íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")

else:
    st.info("ì‹œì‘í•˜ë ¤ë©´ ìœ„ ì˜ì—­ì— CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì‹­ì‹œì˜¤.")
